{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('C:/Users/user/Desktop/WD/ton/HeartRate_StressLevel/Train Data/frequency_domain_features_train.csv')\n",
    "df2 = pd.read_csv('C:/Users/user/Desktop/WD/ton/HeartRate_StressLevel/Train Data/heart_rate_non_linear_features_train.csv')\n",
    "df3 = pd.read_csv('C:/Users/user/Desktop/WD/ton/HeartRate_StressLevel/Train Data/time_domain_features_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MEAN_RR', 'MEDIAN_RR', 'SDRR', 'RMSSD', 'SDSD', 'SDRR_RMSSD', 'HR',\n",
       "       'pNN25', 'pNN50', 'KURT', 'SKEW', 'MEAN_REL_RR', 'MEDIAN_REL_RR',\n",
       "       'SDRR_REL_RR', 'RMSSD_REL_RR', 'SDSD_REL_RR', 'SDRR_RMSSD_REL_RR',\n",
       "       'KURT_REL_RR', 'SKEW_REL_RR', 'uuid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uuid       False    (식별자)\n",
    "VLF        False    (Very Low Frequency : 심한 저주파)\n",
    "VLF_PCT    False    (Percentage of VLF : 전체 power spectrum에서 VLF가 차지하는 정도)\n",
    "LF         False    (Low Frequency : 저주파)\n",
    "LF_PCT     False    (Percentage of LF : 전체 power spectrum에서 LF가 차지하는 정도)\n",
    "LF_NU      False    (정규화된 단위 (Normalized Unit)로 나타낸 LF 구성 요소)\n",
    "HF         False    (High Frequency : 고주파)\n",
    "HF_PCT     False    (Percentage of HF : 전체 power spectrum에서 HF가 차지하는 정도)\n",
    "HF_NU      False    (정규화된 단위 (Normalized Unit)로 나타낸 HF 구성 요소)\n",
    "TP         False    (Total Power : 전체 파워(주파수 스펙트럼의 총량))\n",
    "LF_HF      False    (Ratio of LF to HF)\n",
    "HF_LF      False    (Ratio of HF to LF)\n",
    "dtype: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uuid         False  (식별자)\n",
    "SD1          False  ( Poincaré plot에서 단기 변동성을 나타내는 지표. 일반적으로 RR 간격(심박사이의 시간 간격)의 단기 변동성을 측정)\n",
    "SD2          False  Poincaré plot에서 장기 변동성을 나타내는 지표. 일반적으로 RR 간격의 장기 변동성을 측정\n",
    "sampen       False  (Sample Entropy : 시간 시계열 데이터의 복잡성을 측정하기 위한 지표로, 값이 낮을수록 예측 가능성이 높고, 값이 높을수록 복잡성이 큼)\n",
    "higuci       False  (Higuchi Fractal Dimension : 시간 시계열 데이터의 프랙탈 차원을 측정하여 데이터의 복잡성을 평가)\n",
    "datasetId    False  (Dataset Identifier)\n",
    "condition    False  ('no stress', 'interruption', 'time pressure' 등의 조건이나 상황)\n",
    "dtype: bool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEAN_RR              False  (RR 간격(심박 사이의 시간 간격)의 평균값)\n",
    "MEDIAN_RR            False  (RR 간격의 중앙값)\n",
    "SDRR                 False  (RR 간격의 표준 편차, 심박 변동성의 측정 지표 중 하나로 사용됨)\n",
    "RMSSD                False  (인접한 RR 간격 차이의 제곱 평균의 제곱근, 심박 변동성의 단기 변동성을 측정)\n",
    "SDSD                 False  (인접한 RR 간격 차이의 표준 편차, 단기 변동성을 측정)\n",
    "SDRR_RMSSD           False  (SDRR과 RMSSD의 비율)\n",
    "HR                   False  (HeartRate : 1분당 심박수, bpm)\n",
    "pNN25                False  (인접한 RR 간격 차이가 25ms를 초과하는 비율)\n",
    "pNN50                False  (인접한 RR 간격 차이가 50ms를 초과하는 비율)\n",
    "KURT                 False  (RR 간격의 첨도 (Kurtosis), 데이터 분포의 뾰족함을 측정)\n",
    "SKEW                 False  (RR 간격의 왜도 (Skewness), 데이터 분포의 비대칭성을 측정)\n",
    "MEAN_REL_RR          False  (상대 RR 간격의 평균값)\n",
    "MEDIAN_REL_RR        False  (상대 RR 간격의 중앙값)\n",
    "SDRR_REL_RR          False  (상대 RR 간격의 표준 편차)\n",
    "RMSSD_REL_RR         False  (상대 RR 간격 차이의 제곱 평균의 제곱근)\n",
    "SDSD_REL_RR          False  (상대 RR 간격 차이의 표준 편차)\n",
    "SDRR_RMSSD_REL_RR    False  (SDRR_REL_RR과 RMSSD_REL_RR의 비율)\n",
    "KURT_REL_RR          False  (상대 RR 간격의 첨도)\n",
    "SKEW_REL_RR          False  (상대 RR 간격의 왜도)\n",
    "uuid                 False  (식별자)\n",
    "dtype: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('C:/Users/user/Desktop/WD/ton/HeartRate_StressLevel/Train Data/frequency_domain_features_train.csv')\n",
    "df2 = pd.read_csv('C:/Users/user/Desktop/WD/ton/HeartRate_StressLevel/Train Data/heart_rate_non_linear_features_train.csv')\n",
    "df3 = pd.read_csv('C:/Users/user/Desktop/WD/ton/HeartRate_StressLevel/Train Data/time_domain_features_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 369289 entries, 0 to 369288\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   MEAN_RR            369289 non-null  float64\n",
      " 1   MEDIAN_RR          369289 non-null  float64\n",
      " 2   SDRR               369289 non-null  float64\n",
      " 3   RMSSD              369289 non-null  float64\n",
      " 4   SDSD               369289 non-null  float64\n",
      " 5   SDRR_RMSSD         369289 non-null  float64\n",
      " 6   HR                 369289 non-null  float64\n",
      " 7   pNN25              369289 non-null  float64\n",
      " 8   pNN50              369289 non-null  float64\n",
      " 9   KURT               369289 non-null  float64\n",
      " 10  SKEW               369289 non-null  float64\n",
      " 11  MEAN_REL_RR        369289 non-null  float64\n",
      " 12  MEDIAN_REL_RR      369289 non-null  float64\n",
      " 13  SDRR_REL_RR        369289 non-null  float64\n",
      " 14  RMSSD_REL_RR       369289 non-null  float64\n",
      " 15  SDSD_REL_RR        369289 non-null  float64\n",
      " 16  SDRR_RMSSD_REL_RR  369289 non-null  float64\n",
      " 17  KURT_REL_RR        369289 non-null  float64\n",
      " 18  SKEW_REL_RR        369289 non-null  float64\n",
      " 19  uuid               369289 non-null  object \n",
      "dtypes: float64(19), object(1)\n",
      "memory usage: 56.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#a = df1.columns\n",
    "#b = df2.columns\n",
    "#c = df3.columns\n",
    "#print(a)\n",
    "#print(b)\n",
    "#print(c)\n",
    "#print(df1.info())  # 12 * 369289\n",
    "#print(df2.info())  # 7  * 369289\n",
    "#print(df3.info())   # 20 * 369289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no stress', 'interruption', 'time pressure'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[:,6].unique()\n",
    "# array(['no stress', 'interruption', 'time pressure'], dtype=object)\n",
    "# no stress = 0, interruption & time pressure = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode = {\"condition\": {\"no stress\":0, \"interruption\":1, \"time pressure\":1}}\n",
    "df2.replace(label_encode, inplace=True)\n",
    "df2.iloc[:,6].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df1 = pd.merge(df1, df2, on='uuid', how='inner')\n",
    "#merged_df1.info()  #\n",
    "merged_df2 = pd.merge(df3,merged_df1,on = 'uuid', how='inner')\n",
    "#merged_df2.info()   #  36 *\n",
    "main_df = merged_df2.drop('uuid',axis=1)\n",
    "main_df = merged_df2.drop('uuid',axis=1)\n",
    "\n",
    "#main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369289, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = main_df.iloc[:,35]\n",
    "X = main_df.iloc[:,:35]\n",
    "Y = pd.DataFrame(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features shape:  (369289, 12)\n",
      "Selected features:  [ 3  4  5  7  9 10 16 17 18 22 25 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#SFM\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = LogisticRegression(max_iter= 1000)\n",
    "model.fit(X, Y)\n",
    "sfm = SelectFromModel(model, prefit=True)\n",
    "X_transform = sfm.transform(X)\n",
    "\n",
    "print(\"Selected features shape: \", X_transform.shape) #max_iter = 200 / [ 3  4  5  6  7  9 17 20 22 23]\n",
    "print(\"Selected features: \", sfm.get_support(indices=True)) # [ 0  5  6  7  9 17 20 23 24]\n",
    "#max_iter = 1000 /  [ 3  4  5  7  9 10 16 17 18 22 25 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance: [0.02772392 0.12573882 0.75834433 0.62989287 0.64162406 1.32297716\n",
      " 0.66680172 1.04762705 0.13163509 0.06662925 0.05092457 0.07359784\n",
      " 0.43200954 0.97574461 0.12859703 0.06475749 0.07175272 0.02183628\n",
      " 0.10612932 0.23038371 0.20556576 0.75508063 0.2927422  0.71488274\n",
      " 1.02155765 0.59195289 0.84046992 0.74173196 0.31092738 1.34380666\n",
      " 0.85373289 1.18216683 0.55539145 0.90614892 0.        ]\n",
      "Selected features: [34]\n"
     ]
    }
   ],
   "source": [
    "#RFE -X\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# L1 정규화를 사용하는 로지스틱 회귀\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
    "model.fit(X_scaled, Y)\n",
    "\n",
    "# 선택된 특징\n",
    "importance = np.abs(model.coef_[0])\n",
    "print(\"Feature importance:\", importance)\n",
    "print(\"Selected features:\", np.where(importance < 1e-5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features shape:  (369289, 23)\n",
      "Selected features:  [ 0  1  2  3  4  5  6  7  8  9 17 19 20 21 22 23 24 25 26 27 28 30 31]\n"
     ]
    }
   ],
   "source": [
    "#Variance Threshold\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "threshold = 0.9 # 임계값 설정\n",
    "selector = VarianceThreshold(threshold)\n",
    "X_variance = selector.fit_transform(X)\n",
    "\n",
    "print(\"Selected features shape: \", X_variance.shape)\n",
    "print(\"Selected features: \", selector.get_support(indices=True))\n",
    "\n",
    "#thres 0.5 / [ 0  1  2  3  4  5  6  7  8  9 17 19 20 21 22 23 24 25 26 27 28 30 31]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
